0.1	3.24		This is a download from bbc learning English
3.24	6.72		to find out more visit our website
6.72	12		6 minute English from BBClearningEnglish.com
12	12.44	<v Rob>	Hello,
12.44	13.04		I’m Rob.
13.04	16.64		Welcome to 6 Minute English and with me in the studio is Neil.
16.64	16.92	<v Neil>	Hello,
16.92	17.72		Rob.
17.72	18.4	<v Rob>	Hello.
18.4	19.52		Feeling bright today,
19.52	20		Neil?
20	22.04	<v Neil>	I am feeling quite bright and clever,
22.04	22.56		yes!
22.56	23.4	<v Rob>	That’s good to hear.
23.4	23.64		Well,
23.64	26.52		<strong>you’ll need all your wits about you</strong> –
26.52	30.84		meaning you’ll need to think very quickly in this programme because we’re talking about intelligence,
30.84	31.84		or to be more accurate,
31.84	34.48		<strong>Artificial</strong> Intelligence.
34.48	40.36		And we’ll learn some vocabulary related to the topic so that you can have your own discussion about it.
40.36	40.72		Now,
40.72	41.08		Neil,
41.08	42.88		you know who Professor Stephen Hawking is,
42.88	43.48		right?
43.48	43.84	<v Neil>	Well,
43.84	44.64		of course!
44.64	44.88		Yes.
44.88	47.44		Many people say that he’s a <strong>genius</strong> –
47.44	48.08		in other words,
48.08	48.84		he is very,
48.84	50.56		very intelligent.
50.56	61.92		Professor Hawking is one of the most famous scientists in the world and people remember him for his brilliance and also because he communicates using a <strong>synthetic</strong> voice generated by a computer –
61.92	65.28		synthetic means it’s made from something non-natural.
65.28	67.28		Artificial is similar in meaning –
67.28	72.04		we use it when something is man-made to look or behave like something natural.
72.04	72.32	<v Rob>	Well,
72.32	77.96		Professor Hawking has said recently that efforts to create thinking machines are a threat to our existence.
77.96	82.6		A <strong>threat</strong> means something which can put us in danger.
82.6	82.92		Now,
82.92	83.48		can you imagine that,
83.48	83.88		Neil?!
83.88	84.24	<v Neil>	Well,
84.24	88.68		there’s no denying that good things can come from the creation of Artificial Intelligence.
88.68	95.36		Computers which can think for themselves might be able to find solutions to problems we haven’t been able to solve.
95.36	100.36		But technology is developing quickly and maybe we should consider the consequences.
100.36	103.76		Some of these very clever robots are already surpassing us,
103.76	104.68		Rob.
104.68	108.88		<strong>To surpass</strong> means to have abilities superior to our own.
108.88	109.36	<v Rob>	Yes.
109.36	115.64		Maybe you can remember the headlines when a supercomputer defeated the World Chess Champion Gary Kasparov,
115.64	117.4		to everybody’s astonishment.
117.4	119.08		It was in 1997.
119.08	120.28		What was the computer called,
120.28	120.96		Neil?
120.96	121.68		Was it:
121.68	123.2		a) Red Menace
123.2	125		b) Deep Blue
125	127.2		c) Silver Surfer
127.2	129.32	<v Neil>	I don’t know.
129.32	133.36		I think © is probably not right.
133.36	134.32		I think Deep Blue.
134.32	135.56		That’s (b) Deep Blue.
135.56	136.36	<v Rob>	Okay.
136.36	139.56		You’ll know if you got it right at the end of the programme.
139.56	139.8		Well,
139.8	145.24		our theme is Artificial Intelligence and when we talk about this we have to mention the movies.
145.24	150.92	<v Neil>	Many science fiction movies have explored the idea of bad computers who want to harm us.
150.92	154.08		One example is 2001: A Space Odyssey.
154.08	154.56	<v Rob>	Yes,
154.56	155.28		a good film.
155.28	157.32		And another is The Terminator,
157.32	161.88		a movie in which actor Arnold Schwarzenegger played an <strong>android</strong> from the future.
161.88	164.48		An android is a robot that looks like a human.
164.48	165.16		Have you watched that one,
165.16	165.6		Neil?
165.6	165.96	<v Neil>	Yes,
165.96	166.72		I have.
166.72	169.12		And the android is not very friendly.
169.12	169.4	<v Rob>	No,
169.4	170.28		it’s not.
170.28	173.12		In many movies and books about robots that think,
173.12	176.76		the robots end up rebelling against their creators.
176.76	183.76		But some experts say the risk posed by Artificial Intelligence is not that computers attack us because they hate us.
183.76	186.64		Their problem is related to their efficiency.
186.64	187.6	<v Neil>	What do you mean?
187.6	188.04	<v Rob>	Well,
188.04	191.4		let’s listen to what philosopher Nick Bostrom has to say.
191.4	196.48		He is the founder of the Future of Humanity Institute at Oxford University.
196.48	202.04		He uses three words when describing what’s inside the mind of a thinking computer.
202.04	205.2		This phrase means ‘to meet their objectives’.
205.2	207.92		What’s the phrase he uses?
207.92	219.84	<v Nick Bostrom, philosopher, Future of Humanity Institute at Oxford University>	The bulk of the risk is not in machines being evil or hating humans but rather that they are indifferent to humans and that in <strong>pursuit</strong> of <strong>their</strong> own <strong>goals</strong> we humans would suffer as a side effect.
219.84	225.48		Suppose you had a super intelligent AI whose only goal was to make as many paperclips as possible.
225.48	232		Human bodies consist of <strong>atoms</strong> and those atoms could be used to make a lot of really nice paperclips.
232	239.84		If you want paperclips it turns out that in the pursuit of this you would have instrumental reasons to do things that would be horrible to humanity.
239.84	242.76	<v Neil>	A world in which humans become paperclips -
242.76	243.12		wow,
243.12	244.4		that’s scary!
244.4	247.16		But the phrase which means ‘meet their objectives’
247.16	248.96		is to ‘pursue their goals’.
248.96	249.48	<v Rob>	Yes,
249.48	250.08		it is.
250.08	256.52		So the academic explains that if you’re a computer responsible for producing paperclips,
256.52	259.28		you will pursue your objective at any cost…
259.28	259.56	<v Neil>	…
259.56	263.56		and even use atoms from human bodies to turn them into paperclips!
263.56	265.4		Now that’s a horror story,
265.4	266.2		Rob.
266.2	267.6		If Stephen Hawking is worried,
267.6	268.84		I think I might be too.
268.84	272.4		How can we be sure that Artificial Intelligence –
272.4	274.6		be it either a device or software –
274.6	276.4		will have a <strong>moral compass</strong>?
276.4	276.96	<v Rob>	Ah,
276.96	277.88		a good expression -
277.88	278.76		a moral compass -
278.76	279.56		in other words,
279.56	282.44		an understanding of what is right and what is wrong.
282.44	284.92	<v Neil>	Artificial Intelligence is an interesting topic,
284.92	285.2		Rob.
285.2	287.96		I hope we can chat about it again in the future.
287.96	290.28		But now I’m looking at the clock and we are running out of time,
290.28	291.24		I’m afraid,
291.24	294.08		and I’d like to know if I got the answer to the quiz question right?
294.08	294.8	<v Rob>	Well,
294.8	301.96		my question was about a supercomputer which defeated the World Chess Champion Gary Kasparov in 1997.
301.96	303.56		What was the machine’s name?
303.56	304.8		Was it: Red Menace,
304.8	306.88		Deep Blue or Silver Surfer?
306.88	309.68	<v Neil>	And I think it’s Deep Blue.
309.68	310.56	<v Rob>	Well,
310.56	314.92		it sounds like you are more intelligent than a computer because you got the answer right.
314.92	315.16		Yes,
315.16	316.24		it was Deep Blue.
316.24	320.88		The 1997 match was actually the second one between Kasparov and Deep Blue,
320.88	326.44		a supercomputer designed by the company IBM and it was specialised in chess-playing.
326.44	327.12	<v Neil>	Well,
327.12	330.4		I think I might challenge Deep Blue to a game obviously.
330.4	332.28		I’m a bit of a genius myself.
332.28	332.64	<v Rob>	Very good!
332.64	333.56		Good to hear!
333.56	334.64		Anyway,
334.64	338.16		we’ve just got time to remember some of the words and expressions that we’ve used today,
338.16	338.64		Neil.
338.64	339.68	<v Neil>	They were:
339.68	342.2		you’ll need your wits about you
342.2	344.84		artificial
344.84	347.52		genius
347.52	350.36		synthetic
350.36	352.24		threat
352.24	354.4		to surpass
354.4	357.8		to pursue their goals
357.8	360.6		moral compass
360.6	361.48	<v Rob>	Thank you.
361.48	361.92		Well,
361.92	363.32		that’s it for this programme.
363.32	367.84		Do visit <a href="http://www.bbclearningenglish.com/">bbclearningenglish.com</a> to find more 6 Minute English programmes.
367.84	368.84		Until next time.
368.84	369.8		Goodbye!
369.8	370.76	<v Neil>	Goodbye!
370.76	376.72		6 minute English from BBC.
