This is a download from bbc learning English
to find out more visit our website
6 minute English from BBClearningEnglish.com
<v Catherine> Hello and welcome to 6 Minute English.
I’m Catherine.
<v Rob> And hello,
I’m Rob.
<v Catherine> Today we have another technology topic.
<v Rob> Oh good!
I love technology.
It makes things easier,
it’s fast and means I can have gadgets.
<v Catherine> Do you think that technology can actually do things better than humans?
<v Rob> For some things,
yes.
I think cars that drive themselves will be safer than humans but that will take away some of the pleasure of driving.
So I guess it depends on what you mean by better.
<v Catherine> Good point,
Rob.
And that actually ties in very closely with today’s topic which is <strong>technochauvinism</strong>.
<v Rob> What’s that?
<v Catherine> We’ll find out shortly,
Rob,
but before we do,
today’s quiz question.
Artificial Intelligence,
or A.I.,
is an area of computer science that develops the ability of computers to learn to do things like solve problems or drive cars without crashing.
But in what decade was the term ‘Artificial Intelligence’ coined?
Was it:
a) the 1940s,
b) the 1950s or
c) the 1960s?
<v Rob> I think it’s quite a new expression so I’ll go for c) the 1960s.
<v Catherine> Good luck with that,
Rob,
and we’ll give you the answer later in the programme.
Now,
let’s get back to our topic of <strong>technochauvinism</strong>.
<v Rob> I know what a <strong>chauvinist</strong> is.
It’s someone who thinks that their country or race or sex is better than others.
But how does this relate to technology?
<v Catherine> We’re about to find out.
Meredith Broussard is Professor of Journalism at New York University and she’s written a book called Artificial Unintelligence.
She appeared on the BBC Radio 4 programme More or Less to talk about it.
Listen carefully and find out her definition of <strong>technochauvinism.</strong>
<v Meredith Broussard, Professor of Journalism at New York University> <strong>Technochauvinism</strong> is the idea that technology is always the highest and best solution.
So somehow over the past couple of decades we got into the habit of thinking that doing something with a computer is always the best and most <strong>objective</strong> way to do something and that’s simply not true.
Computers are not <strong>objective</strong>,
they are <strong>proxies</strong> for the people who make them.
<v Catherine> What is Meredith Broussard’s definition of <strong>technochauvinism</strong>?
<v Rob> It’s this idea that using technology is better than not using technology.
<v Catherine> She says that we have this idea that a computer is <strong>objective</strong>.
Something that is <strong>objective</strong> is neutral,
it doesn’t have an opinion,
it’s fair and it’s unbiased –
so it’s the opposite of being a <strong>chauvinist</strong>.
But Meredith Broussard says this is not true.
<v Rob> She argues that computers are not <strong>objective</strong>.
They are <strong>proxies</strong> for the people that make them.
You might know the word <strong>proxy</strong> when you are using your computer in one country and want to look at something that is only available in a different country.
You can use a piece of software called a <strong>proxy</strong> to do that.
<v Catherine> But a <strong>proxy</strong> is also a person or a thing that carries out your wishes and your instructions for you.
So computers are only as smart or as <strong>objective</strong> as the people that programme them.
Computers are <strong>proxies</strong> for their programmers.
Broussard says that believing too much in Artificial Intelligence can make the world worse.
Let’s hear a bit more.
This time find out what serious problems in society does she think may be reflected in AI?
<v Meredith Broussard, Professor of Journalism at New York University> It’s a <strong>nuanced</strong> problem.
What we have is data on the world as it is and we have serious problems with racism,
sexism,
classism,
ageism,
in the world right now so there is no such thing as perfect data.
We also have a problem inside the tech world where the creators of <strong>algorithms</strong> do not have sufficient awareness of social issues such that they can make good technology that gets us closer to a world as it should be.
<v Rob> She said that society has problems with racism,
sexism,
classism and ageism.
<v Catherine> And she says it’s a <strong>nuanced</strong> problem.
A <strong>nuanced</strong> problem is not simple,
but it does have small and important areas which may be hard to spot,
but they need to be considered.
<v Rob> And she also talked about <strong>algorithms</strong> used to program these technological systems.
An <strong>algorithm</strong> is a set of instructions that computers use to perform their tasks.
Essentially it’s the rules that they use to come up with their answers and Broussard believes that technology will reflect the views of those who create the <strong>algorithms</strong>.
<v Catherine> Next time you’re using a piece of software or your favourite app you might find yourself wondering if it’s a useful tool or does it contain these little nuances that reflect the views of the developer.
<v Rob> Right,
Catherine.
How about the answer to this week’s question then?
<v Catherine> I asked in which decade was the term ‘Artificial Intelligence’ coined.
Was it the 40s,
the 50s or the 60s?
<v Rob> And I said the 60s.
<v Catherine> But it was actually the 1950s.
Never mind,
Rob.
Let’s review today’s vocabulary.
<v Rob> Well,
we had a <strong>chauvinist</strong> –
that’s someone who believes their country,
race or sex is better than any others.
<v Catherine> And this gives us <strong>technochauvinism</strong>,
the belief that a technological solution is always a better solution to a problem.
<v Rob> Next -
someone or something that is <strong>objective</strong> is neutral,
fair and balanced.
<v Catherine> A <strong>proxy</strong> is a piece of software but also someone who does something for you,
on your behalf.
A <strong>nuanced</strong> problem is a subtle one,
it’s not a simple case of right or wrong,
in a <strong>nuanced</strong> problem there are small but important things that you need to consider.
<v Rob> And an <strong>algorithm</strong> is a set of software instructions for a computer system.
<v Catherine> Well,
that’s all we have time for today.
Goodbye for now.
<v Rob> Bye bye!
6 minute English from BBC.
